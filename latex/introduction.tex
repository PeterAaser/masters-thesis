\chapter{Introduction}
\epigraph{They're trying to understand what space is. That's tough for them.
They break distances down into concentrations of chemicals. For them, space is a
range of taste intensities.}{Greg Bear, Blood Music}
Countless manhours have been spent improving the design and manufacturing
process of the digital computer, creating more and more complex architectures
capable of operating at ever greater speeds while maintaining stability, as even
a single glitch can cause the program to crash.
%
Neurons on the other hand have no architectural blueprint to follow, but still
organize themselves into networks capable of solving complex tasks, with far
greater energy efficiency, robustness and parallellism than any designed
processor.
%
Inspired by work done in the field of material computing systems such as the
mecobo platform of nascence [citation needed], living neural networks grown from
human stem cells \emph{in vitro} on \emph{Micro Electrode Arrays} (MEA) are interfaced
with a digital computer, forming a hybrid neuro-digital system.
%
This system utilizes the theoretical framework of \emph{Reservoir Computing} to
help translate between the digital and biological parts of the system, allowing
it to solve simple tasks as a proof of concept.\\ \\
In the 50's and 60's there was much optimism in the burgeoning field of
artificial intelligence. In 1965 H. A. Simon claimed ``machines will be capable,
within twenty years, of doing any work a man can
do.''\cite{vardi_artificial_nodate} , while Marvin Minsky boldly claimed in 1967
that ``Within a generation ... the problem of creating 'artificial intelligence'
will substantially be solved.'' \cite{noauthor_marvin_nodate}.
These claims seem ridiculous now, but at the time the optimism made sense. After
all great strides was made in symbolic programming, computers had finally become
powerful enough to efficiently manipulate logic symbols such as predicates,
negations and implications. With these programs the machine could inferr
conclusions based on previously known information using symbolic logic,
mimmicking the high level reasoning that humans are capable of. While the
computers at the time were only capable of very simple logic inference, such as
concluding the grass was wet based on prior knowledge it had recently rained, it
was believed that the machines ability to infer would grow at the same pace as
processor speeds.
The driving force behind the great leaps made in symbolic computation was the
exponential growth in transistors per area, dubbed moore's law.
This growth allowed processors to maintain exponential performance increases
without straying from the fundamental Von Neumann architecture, sequentially
performing instructions to manipulate memory.
With these performance gains yesteryears intractable problems were turned into
routine operations, and AI it was thought, was no different. Why then did Minsky's
predictions fail so badly?
In short, processors are \emph{designed} in a top down fashion to perform
an instruction set of logical operations, which in turn allows us to design and run programs on them,
for instance programs that operate on logical propositions superficially
similarly to human reasoning.
As complex as they are, each component in a processor has an obvious purpose
(such as adding numbers) and like clockwork these parts work together to execute
the program.
The brain on the other hand is the result of a self-organizing process forming a
network where each component works in parallel leading to a global behavior much
greater than the sum of its parts.
In order to understand the difference, it is quite revealing that humans are so
bad at simple arithmetic compared to the processor.
This is because unlike processors, there is no adder neuron, thus our ability to
add numbers is a property that arises from the collective behavior of neurons,
and cannot be traced back to any single neuron. The goal of the
processor designer is to provide a component capable of addition, while the
``goal'' of the neurons is to create a network whose dynamics are capable of
responding to any input, including arithmetic.
\\ \\

Unconvential computing, as implied by the name, comes in many forms such as
buckets of water \cite{fernando_pattern_2003}, or blobs of carbon nanotubes [cite nascence].
These approaches utilize the inherent computation that happens in all physical
processes.
% Introduces how computation occurs "naturally"
Consider the effort spent modelling and simulating snow [Cite SIGGRAPH frozen
paper] used in motion pictures such as Disney's frozen. Dozens of machines in
large rendering farms spend weeks rendering the snow in final movie, however if
you bring some dynamite and a helicopter nature will gladly provide you with an
avalanche ``for free''.\\
% Discuss the difficulties of this computation
% Problem: I want to introduce reservoir computing here too, and it's just not
% meshing well with the narrative of reservoir computing. Also the whole
% avalanche thing feels too lengthy as it is now
Motion pictures aside, all natural
processes, going from order to entropy are performing calculations, the only
difference between avalanches and silicone processors from a computational
standpoint is the fact that the silicone processor has been shaped in such a way
that the process happens in an orderly, controlled fashion. Avalanches are
unlikely to have a big impact on the computing world.
Computation may occur, but it is far too unstructured to have any
practical use. Still, the processes governing an avalanche are not that
different from the processes happening in the primordial soup, save for one key
difference, in the primordial soup life formed, and with life came evolution.
What is the difference between an avalanche and slime mould? While it's
certainly relevant to mention that an avalanche might crush you, from a
computational standpoint the difference is that the process that unfolds in
slime mould serves a purpose. The slime mould seeks food which allows it to
spread and propagate its genes. In short, it responds to its environment,
reacting to sources of food and avoiding danger. Indeed, the slime mould can be
directly applied to solve computational problems, such as Adamatzky's
application of mould for road planning [Cite Adamatzky Mould Paper]. The
interconnected nature of life and computation is perhaps best shown in DNA,
which can even be directly utilized in computations such as in Adlemans DNA
computer [Cite Adleman].\\
Still, the most impressive example of computation is the human brain, vastly
outperforming silicone computers in complex tasks such as the manufacturing of
funny internet referential humor. 
% hehe
The vast complexity of the human brain has made it a very difficult subject to
study and copy. Rather than understanding the human brain as a whole a more
feasible approach is to understand the underlying processes that allow neural
networks to self-organize into computationally capable networks.
In [Cite DeMarse flight controller] a neural network is grown in an MEA and
interfaced with a flight simulator. [Cite AHDNN] follows a similar approach,
using neurons to control a simple robot. The contribution presented in this
paper builds on this work, but adding RC...

\cleardoublepage

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End: